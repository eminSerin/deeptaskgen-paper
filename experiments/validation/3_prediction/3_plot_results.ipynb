{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import pickle\n",
    "import sys\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import permutation_test, ttest_rel\n",
    "from sklearn.exceptions import InconsistentVersionWarning\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "sys.path.append(op.abspath(op.join(op.abspath(\"\"), \"..\")))\n",
    "from utils.utils import correlation_score\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"talk\", font_scale=1, rc={\"axes.labelpad\": 10})\n",
    "pd.set_option(\"display.float_format\", \"{:.3}\".format)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "pd.set_option(\"display.float_format\", \"{:.3}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABS_PATH = sys.path[-1]\n",
    "RESULTS_PATH = op.join(ABS_PATH, \"3_prediction/results\")\n",
    "FIG_DIR = op.join(ABS_PATH, \"3_prediction/figures\")\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "PALETTE = {\n",
    "    \"Actual\": \"#283F94\",\n",
    "    \"Predicted\": \"#AE3033\",\n",
    "}\n",
    "\n",
    "CONTRASTS = (\n",
    "    \"REST\",\n",
    "    \"EMOTION FACES-SHAPES\",\n",
    "    \"GAMBLING REWARD\",\n",
    "    \"LANGUAGE MATH-STORY\",\n",
    "    \"RELATIONAL REL\",\n",
    "    \"SOCIAL TOM-RANDOM\",\n",
    "    \"WM 2BK-0BK\",\n",
    "    \"MOTOR AVG\",\n",
    ")\n",
    "\n",
    "CONTRASTS_MAP = {\n",
    "    \"ukb_actual\": (\n",
    "        \"rest\",\n",
    "        \"emotion_faces-shapes\",\n",
    "    ),\n",
    "    \"ukb_pred\": (\n",
    "        \"emotion_faces-shapes\",\n",
    "        \"gambling_reward\",\n",
    "        \"language_math-story\",\n",
    "        \"relational_rel\",\n",
    "        \"social_tom-random\",\n",
    "        \"wm_2bk-0bk\",\n",
    "        \"motor_avg\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "SCORE_FUNCS = {\n",
    "    \"age\": correlation_score,\n",
    "    \"fluid\": correlation_score,\n",
    "    \"sex\": balanced_accuracy_score,\n",
    "    \"strength\": correlation_score,\n",
    "    \"overall_health\": correlation_score,\n",
    "    \"alcohol_freq\": correlation_score,\n",
    "    \"beer_freq\": correlation_score,\n",
    "    \"depression\": balanced_accuracy_score,\n",
    "    \"hypertension\": balanced_accuracy_score,\n",
    "    \"neuroticism\": correlation_score,\n",
    "    \"GAD\": correlation_score,\n",
    "    \"PHQ\": correlation_score,\n",
    "    \"RDS\": correlation_score,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn of version warnings.\n",
    "warnings.filterwarnings(\"ignore\", category=InconsistentVersionWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "# Prepare dataframes for plotting.\n",
    "def results_files_dict():\n",
    "    pred_scores = defaultdict(lambda: defaultdict(lambda: defaultdict(dict)))\n",
    "    for target in SCORE_FUNCS.keys():\n",
    "        for dset in CONTRASTS_MAP:\n",
    "            for cont in CONTRASTS_MAP[dset]:\n",
    "                cont = cont.replace(\" \", \"_\").lower()\n",
    "                try:\n",
    "                    fname = glob(\n",
    "                        op.join(\n",
    "                            RESULTS_PATH,\n",
    "                            dset,\n",
    "                            f\"{dset}_{target}_{cont}_ridge*_perm.pkl\",\n",
    "                        )\n",
    "                    )[0]\n",
    "                    pred_scores[target][dset][cont] = fname\n",
    "                except:\n",
    "                    print(f\"Could not find {dset}_{target}_{cont}.pkl\")\n",
    "                    pass\n",
    "    return pred_scores\n",
    "\n",
    "\n",
    "def compute_scores(pred_scores):\n",
    "    perm_scores = {}\n",
    "    cv_scores = {}\n",
    "    for target in pred_scores:\n",
    "        perm_scores[target] = {}\n",
    "        _scores = pd.DataFrame()\n",
    "        for dset in pred_scores[target]:\n",
    "            perm_scores[target][dset] = {}\n",
    "            for i, task in enumerate(pred_scores[target][dset]):\n",
    "                preds = pickle.load(open(pred_scores[target][dset][task], \"rb\"))\n",
    "                if i == 0:\n",
    "                    print(\n",
    "                        f\"Dataset: {dset}, Target: {target}, n = {np.hstack(preds[0]['y_true']).shape[0]}\"\n",
    "                    )\n",
    "                __sc = []\n",
    "                for pred in preds:\n",
    "                    __sc.append(\n",
    "                        [\n",
    "                            SCORE_FUNCS[target](y_true, y_pred)\n",
    "                            for y_true, y_pred in zip(pred[\"y_true\"], pred[\"y_pred\"])\n",
    "                        ]\n",
    "                    )\n",
    "                perm_scores[target][dset][task] = __sc\n",
    "                tmp = pd.DataFrame(__sc[0], columns=[\"CV Score\"]).assign(\n",
    "                    Contrast=task.replace(\"_\", \"\\n\").upper(),\n",
    "                    Dataset=dset,\n",
    "                    Actual=\"Actual\"\n",
    "                    if \"finetune\" not in dset\n",
    "                    else dset.split(\"_\")[1].capitalize(),\n",
    "                )\n",
    "                _scores = pd.concat(\n",
    "                    [\n",
    "                        _scores,\n",
    "                        tmp,\n",
    "                    ],\n",
    "                    axis=0,\n",
    "                )\n",
    "        cv_scores[target] = _scores\n",
    "    return cv_scores, perm_scores\n",
    "\n",
    "\n",
    "cv_scores, perm_scores = compute_scores(results_files_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## HELPER FUNCTIONS\n",
    "def comp_perm_sig_cv(perms):\n",
    "    \"\"\"Compute permutation significance from given permutation scores.\"\"\"\n",
    "    cv = np.mean(perms[0])\n",
    "    perm_cv = [np.mean(p) for p in perms]\n",
    "    return cv, (perm_cv >= cv).mean()\n",
    "\n",
    "\n",
    "def comp_perm_sig_ttest(main, comp):\n",
    "    \"\"\"Compute permutation significance from given two sets of permutation scores.\"\"\"\n",
    "    t, _ = ttest_rel(main[0], comp[0])\n",
    "    perm_t = [ttest_rel(m, c)[0] for m, c in zip(main, comp)]\n",
    "    if t > 0:\n",
    "        return t, (perm_t >= t).mean()\n",
    "    else:\n",
    "        return t, (perm_t <= t).mean()\n",
    "\n",
    "\n",
    "def cliffs_delta(group1, group2):\n",
    "    \"\"\"\n",
    "    Calculate Cliff's Delta effect size between two groups.\n",
    "\n",
    "    Parameters:\n",
    "    group1, group2 : array-like\n",
    "        The two groups to compare\n",
    "\n",
    "    Returns:\n",
    "    float : Cliff's Delta (-1 to +1)\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays for efficient computation\n",
    "    g1, g2 = np.array(group1), np.array(group2)\n",
    "\n",
    "    # Use broadcasting to compute all pairwise comparisons at once\n",
    "    greater = g1[:, None] > g2\n",
    "    less = g1[:, None] < g2\n",
    "\n",
    "    # Sum up differences and normalize\n",
    "    dominance = np.sum(greater) - np.sum(less)\n",
    "    delta = dominance / (len(g1) * len(g2))\n",
    "\n",
    "    return delta\n",
    "\n",
    "\n",
    "def compare_tasks(perm_scores, target):\n",
    "    \"\"\"\n",
    "    Compare predicted and actual contrasts for a given target.\n",
    "\n",
    "    Args:\n",
    "        perm_scores (dict): Dictionary containing permutation scores for different contrasts.\n",
    "        target (str): Target contrast.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing the comparison results.\n",
    "    \"\"\"\n",
    "    tasks_comp = []\n",
    "    for task in CONTRASTS_MAP[\"ukb_finetune\"]:\n",
    "        main = perm_scores[target][\"ukb_finetune\"][task]\n",
    "        for comp_task in CONTRASTS_MAP[\"ukb\"]:\n",
    "            comp = perm_scores[target][\"ukb\"][comp_task]\n",
    "            t, t_sig = comp_perm_sig_ttest(main, comp)\n",
    "            delta = cliffs_delta(main[0], comp[0])\n",
    "            tasks_comp.append(\n",
    "                {\n",
    "                    \"Predicted Contrast\": task,\n",
    "                    \"Actual Contrast\": comp_task,\n",
    "                    \"t\": t,\n",
    "                    \"p\": t_sig,\n",
    "                    \"delta\": delta,\n",
    "                }\n",
    "            )\n",
    "    t, t_sig = comp_perm_sig_ttest(\n",
    "        perm_scores[target][\"ukb\"][\"connectome_d50\"],\n",
    "        perm_scores[target][\"ukb\"][\"emotion_faces-shapes\"],\n",
    "    )\n",
    "    delta = cliffs_delta(\n",
    "        perm_scores[target][\"ukb\"][\"connectome_d50\"][0],\n",
    "        perm_scores[target][\"ukb\"][\"emotion_faces-shapes\"][0],\n",
    "    )\n",
    "    tasks_comp.append(\n",
    "        {\n",
    "            \"Predicted Contrast\": \"connectome_d50\",\n",
    "            \"Actual Contrast\": \"emotion_faces-shapes\",\n",
    "            \"t\": t,\n",
    "            \"p\": t_sig,\n",
    "            \"delta\": delta,\n",
    "        }\n",
    "    )\n",
    "    perm_results = pd.DataFrame(tasks_comp)\n",
    "    perm_results[\"p_value_fdr\"] = fdrcorrection(perm_results[\"p\"])[1]\n",
    "    return perm_results\n",
    "\n",
    "\n",
    "def print_permutation_significance(perm_scores, target):\n",
    "    \"\"\"\n",
    "    Prints the permutation significance for each task in each dataset.\n",
    "\n",
    "    Args:\n",
    "        perm_scores (dict): A dictionary containing permutation scores for each target, dataset, and task.\n",
    "        target (str): The target for which permutation significance is calculated.\n",
    "\n",
    "    Returns:\n",
    "        sigs (list): A list containing the permutation significance results.\n",
    "    \"\"\"\n",
    "    sigs = []\n",
    "    for dset in CONTRASTS_MAP.keys():\n",
    "        for task in CONTRASTS_MAP[dset]:\n",
    "            stat, sig = comp_perm_sig_cv(perm_scores[target][dset][task])\n",
    "            print(\n",
    "                f\"Permutation significance for {task} in {dset}: {stat:.3f}, p = {sig:.3f}\"\n",
    "            )\n",
    "            sigs.append(\n",
    "                {\n",
    "                    \"Dataset\": dset,\n",
    "                    \"Contrast\": task.upper().replace(\"_\", \"\\n\"),\n",
    "                    \"CV Score\": stat,\n",
    "                    \"p\": sig,\n",
    "                    \"Actual\": \"Actual\"\n",
    "                    if \"finetune\" not in dset\n",
    "                    else dset.split(\"_\")[1].capitalize(),\n",
    "                }\n",
    "            )\n",
    "    return pd.DataFrame(sigs)\n",
    "\n",
    "\n",
    "## Function for plotting CV scores\n",
    "def plot_cv_scores(target, ylim, sigs=None):\n",
    "    plt.figure(figsize=(11, 6), dpi=300)\n",
    "    plot_df = cv_scores[target].dropna()\n",
    "    if sigs is not None:\n",
    "        sigs[\"Dataset\"] = sigs[\"Dataset\"]\n",
    "        plot_df = plot_df.merge(\n",
    "            sigs.drop(\"CV Score\", axis=1),\n",
    "            on=[\"Dataset\", \"Contrast\", \"Actual\"],\n",
    "            how=\"left\",\n",
    "        )\n",
    "        plot_df[\"Alpha\"] = plot_df[\"p\"].apply(lambda x: 0.25 if x >= 0.05 else 0.75)\n",
    "    else:\n",
    "        plot_df[\"Alpha\"] = 0.75\n",
    "    unique_contrasts = plot_df[\"Contrast\"].unique()\n",
    "    unique_actual = plot_df[\"Actual\"].unique()\n",
    "    for contrast in unique_contrasts:\n",
    "        for actual in unique_actual:\n",
    "            filter_df = plot_df[\n",
    "                (plot_df[\"Contrast\"] == contrast) & (plot_df[\"Actual\"] == actual)\n",
    "            ]\n",
    "            if not filter_df.empty:\n",
    "                sns.pointplot(\n",
    "                    data=filter_df,\n",
    "                    x=\"Contrast\",\n",
    "                    y=\"CV Score\",\n",
    "                    hue=\"Actual\",\n",
    "                    errorbar=\"sd\",\n",
    "                    linestyles=\"\",\n",
    "                    palette=PALETTE,\n",
    "                    alpha=filter_df[\"Alpha\"].iloc[0],  # Set alpha for each contrast\n",
    "                ).set(\n",
    "                    xticklabels=[],\n",
    "                    yticklabels=[],\n",
    "                )\n",
    "    plt.ylim(ylim)\n",
    "    sns.despine(offset=10, trim=True)\n",
    "    plt.legend(loc=\"right\", bbox_to_anchor=(1.15, 0.5)).set_visible(False)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.savefig(op.join(FIG_DIR, f\"{target}.pdf\"), bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "def print_formatted_compare_tasks(results_df):\n",
    "    \"\"\"\n",
    "    Formats and prints task comparison results based on the provided structure,\n",
    "    using the 'p_value_fdr' column for p-values.\n",
    "\n",
    "    Args:\n",
    "        results_df (pd.DataFrame): DataFrame with columns including\n",
    "                                   'Predicted Contrast', 'Actual Contrast',\n",
    "                                   't', 'p_value_fdr', and 'delta'.\n",
    "    \"\"\"\n",
    "    actual_emotion_key = \"emotion_faces-shapes\"\n",
    "    actual_connectome_key = (\n",
    "        \"connectome_d50\"  # Assuming this key represents Resting State Connectome\n",
    "    )\n",
    "\n",
    "    # --- Name mapping for display ---\n",
    "    name_map = {\n",
    "        \"emotion_faces-shapes\": \"EMOTION FACES-SHAPES\",\n",
    "        \"gambling_reward\": \"GAMBLING REWARD\",\n",
    "        \"language_math-story\": \"LANGUAGE MATH-STORY\",\n",
    "        \"motor_avg\": \"MOTOR AVG\",\n",
    "        \"relational_rel\": \"RELATIONAL REL\",\n",
    "        \"social_tom-random\": \"SOCIAL TOM-RANDOM\",\n",
    "        \"wm_2bk-0bk\": \"WM 2BK-0BK\",\n",
    "        \"connectome_d50\": \"Resting State Connectome\",\n",
    "    }\n",
    "\n",
    "    # --- Verify input columns ---\n",
    "    # Use 'p_value_fdr' instead of 'p'\n",
    "    required_cols = [\n",
    "        \"Predicted Contrast\",\n",
    "        \"Actual Contrast\",\n",
    "        \"t\",\n",
    "        \"p_value_fdr\",\n",
    "        \"delta\",\n",
    "    ]\n",
    "    if not all(col in results_df.columns for col in required_cols):\n",
    "        missing = [col for col in required_cols if col not in results_df.columns]\n",
    "        print(f\"Error: Input DataFrame is missing required columns: {missing}\")\n",
    "        return\n",
    "\n",
    "    # --- Prepare data views ---\n",
    "    # Use .copy() to avoid potential SettingWithCopyWarning\n",
    "    vs_emotion = (\n",
    "        results_df[results_df[\"Actual Contrast\"] == actual_emotion_key]\n",
    "        .set_index(\"Predicted Contrast\")\n",
    "        .copy()\n",
    "    )\n",
    "    vs_connectome = (\n",
    "        results_df[results_df[\"Actual Contrast\"] == actual_connectome_key]\n",
    "        .set_index(\"Predicted Contrast\")\n",
    "        .copy()\n",
    "    )\n",
    "\n",
    "    # --- Build the main table ('Predicted' rows) ---\n",
    "    # Select 'p_value_fdr' and rename it to 'p_emo'/'p_conn'\n",
    "    df_emo = vs_emotion[[\"t\", \"p_value_fdr\", \"delta\"]].rename(\n",
    "        columns={\"t\": \"t_emo\", \"p_value_fdr\": \"p_emo\", \"delta\": \"delta_emo\"}\n",
    "    )\n",
    "    df_conn = vs_connectome[[\"t\", \"p_value_fdr\", \"delta\"]].rename(\n",
    "        columns={\"t\": \"t_conn\", \"p_value_fdr\": \"p_conn\", \"delta\": \"delta_conn\"}\n",
    "    )\n",
    "\n",
    "    # Merge the two comparison types based on the predicted contrast index\n",
    "    merged_df = pd.merge(\n",
    "        df_emo, df_conn, left_index=True, right_index=True, how=\"outer\"\n",
    "    )\n",
    "\n",
    "    # Separate the main prediction rows from the 'actual connectome' row index\n",
    "    main_contrasts_idx = merged_df.index[merged_df.index != actual_connectome_key]\n",
    "    main_table = merged_df.loc[main_contrasts_idx].copy()\n",
    "\n",
    "    # --- Prepare the last row ('Actual' row data) ---\n",
    "    last_row_stats = None\n",
    "    if actual_connectome_key in vs_emotion.index:\n",
    "        # Get stats for 'Resting State Connectome' compared against 'EMOTION FACES-SHAPES'\n",
    "        # Use 'p_value_fdr' here\n",
    "        last_row_stats = vs_emotion.loc[\n",
    "            actual_connectome_key, [\"t\", \"p_value_fdr\", \"delta\"]\n",
    "        ]\n",
    "\n",
    "    # --- Format and Print ---\n",
    "\n",
    "    # Rename index using the map for display\n",
    "    main_table.index = main_table.index.map(lambda x: name_map.get(x, x))\n",
    "    main_table.index.name = \"Task Contrast\"\n",
    "\n",
    "    # Create multi-level columns to match the target structure\n",
    "    # The display names 'p' are kept\n",
    "    main_table.columns = pd.MultiIndex.from_tuples(\n",
    "        [\n",
    "            (\"vs. Actual EMOTION FACES-SHAPES\", \"t\"),\n",
    "            (\"vs. Actual EMOTION FACES-SHAPES\", \"p\"),  # Display header remains 'p'\n",
    "            (\"vs. Actual EMOTION FACES-SHAPES\", \"δ\"),\n",
    "            (\"vs. Resting State Connectome\", \"t\"),\n",
    "            (\"vs. Resting State Connectome\", \"p\"),  # Display header remains 'p'\n",
    "            (\"vs. Resting State Connectome\", \"δ\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Formatting functions for numerical values (handling NaN)\n",
    "    def format_t(x):\n",
    "        return f\"{x:.2f}\" if pd.notna(x) else \"-\"\n",
    "\n",
    "    def format_p(x):\n",
    "        return (\n",
    "            f\"{x:.3f}\" if pd.notna(x) else \"-\"\n",
    "        )  # This will format the p_value_fdr value\n",
    "\n",
    "    def format_delta_emo(x):\n",
    "        return f\"{x:.1f}\" if pd.notna(x) else \"-\"  # Delta vs Emotion (e.g., 1.0)\n",
    "\n",
    "    def format_delta_conn(x):\n",
    "        return f\"{x:.2f}\" if pd.notna(x) else \"-\"  # Delta vs Connectome (e.g., 0.84)\n",
    "\n",
    "    # Apply formatting to the main table DataFrame\n",
    "    main_table[(\"vs. Actual EMOTION FACES-SHAPES\", \"t\")] = main_table[\n",
    "        (\"vs. Actual EMOTION FACES-SHAPES\", \"t\")\n",
    "    ].map(format_t)\n",
    "    main_table[(\"vs. Actual EMOTION FACES-SHAPES\", \"p\")] = main_table[\n",
    "        (\"vs. Actual EMOTION FACES-SHAPES\", \"p\")\n",
    "    ].map(format_p)  # Apply p format\n",
    "    main_table[(\"vs. Actual EMOTION FACES-SHAPES\", \"δ\")] = main_table[\n",
    "        (\"vs. Actual EMOTION FACES-SHAPES\", \"δ\")\n",
    "    ].map(format_delta_emo)\n",
    "    main_table[(\"vs. Resting State Connectome\", \"t\")] = main_table[\n",
    "        (\"vs. Resting State Connectome\", \"t\")\n",
    "    ].map(format_t)\n",
    "    main_table[(\"vs. Resting State Connectome\", \"p\")] = main_table[\n",
    "        (\"vs. Resting State Connectome\", \"p\")\n",
    "    ].map(format_p)  # Apply p format\n",
    "    main_table[(\"vs. Resting State Connectome\", \"δ\")] = main_table[\n",
    "        (\"vs. Resting State Connectome\", \"δ\")\n",
    "    ].map(format_delta_conn)\n",
    "\n",
    "    # --- Print the Formatted Output ---\n",
    "\n",
    "    # Print header for the 'Predicted' section\n",
    "    print(\n",
    "        \" \" * 25\n",
    "        + f\"| {'vs. Actual EMOTION FACES-SHAPES':^30} | {'vs. Resting State Connectome':^30}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{'Task Contrast':<25} | {'t':>8} {'p':>10} {'δ':>8} | {'t':>8} {'p':>10} {'δ':>8}\"\n",
    "    )\n",
    "    print(\"-\" * 85)\n",
    "\n",
    "    # Print the main table rows ('Predicted')\n",
    "    for index, row in main_table.iterrows():\n",
    "        print(\n",
    "            f\"{index:<25} | \"\n",
    "            f\"{row[('vs. Actual EMOTION FACES-SHAPES', 't')]:>8} \"\n",
    "            f\"{row[('vs. Actual EMOTION FACES-SHAPES', 'p')]:>10} \"  # Uses formatted p_value_fdr\n",
    "            f\"{row[('vs. Actual EMOTION FACES-SHAPES', 'δ')]:>8} | \"\n",
    "            f\"{row[('vs. Resting State Connectome', 't')]:>8} \"\n",
    "            f\"{row[('vs. Resting State Connectome', 'p')]:>10} \"  # Uses formatted p_value_fdr\n",
    "            f\"{row[('vs. Resting State Connectome', 'δ')]:>8}\"\n",
    "        )\n",
    "\n",
    "    print(\"-\" * 85)  # Separator line\n",
    "\n",
    "    # Print the 'Actual' section (last row)\n",
    "    print(f\"{'Actual':<25} |\")  # Label for the 'Actual' group\n",
    "    if last_row_stats is not None:\n",
    "        actual_row_name = name_map.get(actual_connectome_key, actual_connectome_key)\n",
    "        # Use 'p_value_fdr' from last_row_stats for formatting\n",
    "        print(\n",
    "            f\"{actual_row_name:<25} | \"\n",
    "            f\"{format_t(last_row_stats['t']):>8} \"\n",
    "            f\"{format_p(last_row_stats['p_value_fdr']):>10} \"  # Format p_value_fdr\n",
    "            f\"{format_delta_emo(last_row_stats['delta']):>8} | \"\n",
    "            f\"{'-':>8} {'-':>10} {'-':>8}\"\n",
    "        )  # No comparison vs connectome here\n",
    "    else:\n",
    "        print(\n",
    "            f\"{name_map.get(actual_connectome_key, actual_connectome_key):<25} | {'Data not found':^60}\"\n",
    "        )\n",
    "\n",
    "    print(\"-\" * 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "target = \"age\"\n",
    "sigs = print_permutation_significance(perm_scores, target)\n",
    "plot_cv_scores(target, (0.3, 0.61), sigs=sigs)\n",
    "print_formatted_compare_tasks(compare_tasks(perm_scores, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex\n",
    "target = \"sex\"\n",
    "sigs = print_permutation_significance(perm_scores, target)\n",
    "plot_cv_scores(target, (0.5, 1), sigs=sigs)\n",
    "print_formatted_compare_tasks(compare_tasks(perm_scores, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fluid Intelligence\n",
    "target = \"fluid\"\n",
    "sigs = print_permutation_significance(perm_scores, target)\n",
    "plot_cv_scores(target, (-0.1, 0.301), sigs=sigs)\n",
    "print_formatted_compare_tasks(compare_tasks(perm_scores, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grip Strength\n",
    "target = \"strength\"\n",
    "sigs = print_permutation_significance(perm_scores, target)\n",
    "plot_cv_scores(target, (0, 0.601), sigs=sigs)\n",
    "comp_results = compare_tasks(perm_scores, target)\n",
    "print_formatted_compare_tasks(comp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall Health\n",
    "target = \"overall_health\"\n",
    "sigs = print_permutation_significance(perm_scores, target)\n",
    "plot_cv_scores(target, (-0.2, 0.2), sigs=sigs)\n",
    "comp_results = compare_tasks(perm_scores, target)\n",
    "print_formatted_compare_tasks(comp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depression\n",
    "target = \"depression\"\n",
    "sigs = print_permutation_significance(perm_scores, target)\n",
    "plot_cv_scores(target, (0.4, 0.601), sigs=sigs)\n",
    "comp_results = compare_tasks(perm_scores, target)\n",
    "print_formatted_compare_tasks(comp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypertension\n",
    "target = \"hypertension\"\n",
    "sigs = print_permutation_significance(perm_scores, target)\n",
    "plot_cv_scores(target, (0.4, 0.601), sigs=sigs)\n",
    "comp_results = compare_tasks(perm_scores, target)\n",
    "print_formatted_compare_tasks(comp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alcohol Freq\n",
    "target = \"alcohol_freq\"\n",
    "sigs = print_permutation_significance(perm_scores, target)\n",
    "plot_cv_scores(target, (-0.2, 0.2), sigs=sigs)\n",
    "comp_results = compare_tasks(perm_scores, target)\n",
    "print_formatted_compare_tasks(comp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beer Freq\n",
    "target = \"beer_freq\"\n",
    "sigs = print_permutation_significance(perm_scores, target)\n",
    "plot_cv_scores(target, (0, 0.36), sigs=sigs)\n",
    "comp_results = compare_tasks(perm_scores, target)\n",
    "print_formatted_compare_tasks(comp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neuroticism\n",
    "target = \"neuroticism\"\n",
    "sigs = print_permutation_significance(perm_scores, target)\n",
    "plot_cv_scores(target, sigs=sigs, ylim=(-0.2, 0.2))\n",
    "comp_results = compare_tasks(perm_scores, target)\n",
    "print_formatted_compare_tasks(comp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAD\n",
    "target = \"GAD\"\n",
    "sigs = print_permutation_significance(perm_scores, target)\n",
    "plot_cv_scores(target, sigs=sigs, ylim=(-0.2, 0.2))\n",
    "comp_results = compare_tasks(perm_scores, target)\n",
    "print_formatted_compare_tasks(comp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHQ\n",
    "target = \"PHQ\"\n",
    "sigs = print_permutation_significance(perm_scores, target)\n",
    "plot_cv_scores(target, sigs=sigs, ylim=(-0.2, 0.2))\n",
    "comp_results = compare_tasks(perm_scores, target)\n",
    "print_formatted_compare_tasks(comp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDS\n",
    "target = \"RDS\"\n",
    "sigs = print_permutation_significance(perm_scores, target)\n",
    "plot_cv_scores(target, sigs=sigs, ylim=(-0.2, 0.2))\n",
    "comp_results = compare_tasks(perm_scores, target)\n",
    "print_formatted_compare_tasks(comp_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
