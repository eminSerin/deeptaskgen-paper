{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import permutation_test, ttest_rel\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"talk\", font_scale=1.2, rc={\"axes.labelpad\": 10})\n",
    "pd.set_option(\"display.float_format\", \"{:.3}\".format)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "pd.set_option(\"display.float_format\", \"{:.3}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "def load_corr_wrapper(path):\n",
    "    return np.load(path)\n",
    "\n",
    "\n",
    "def extract_diagonal(mat):\n",
    "    n_dims = len(mat.shape)\n",
    "    if n_dims == 3:\n",
    "        raise ValueError(\"Input matrix must be 2D\")\n",
    "    return np.array([mat[i, i] for i in range(mat.shape[0])])\n",
    "\n",
    "\n",
    "def fingerprinting_score(corr_matrix):\n",
    "    \"\"\"\n",
    "    Computes the fingerprinting score from a correlation matrix.\n",
    "\n",
    "    Parameters:\n",
    "    corr_matrix (numpy.ndarray): A 2D numpy array containing the correlation matrix.\n",
    "\n",
    "    Returns:\n",
    "    float: The fingerprinting score.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store the fingerprinting score for each row\n",
    "    fp_score = []\n",
    "    diag_score = np.diag(corr_matrix).mean()\n",
    "    # Iterate over each row in the correlation matrix\n",
    "    for row_index, row in enumerate(corr_matrix):\n",
    "        # Check if the maximum value in the row is on the diagonal\n",
    "        is_max_on_diagonal = np.argmax(row) == row_index\n",
    "\n",
    "        # Check if the diagonal element is the only occurrence of that value in the row\n",
    "        is_unique_in_row = np.count_nonzero(row == row[row_index]) == 1\n",
    "\n",
    "        # If both conditions are met, append True to the fp_score list, otherwise append False\n",
    "        fp_score.append(is_max_on_diagonal and is_unique_in_row)\n",
    "\n",
    "    # Calculate the fingerprinting score as the mean of the fp_score list\n",
    "    return np.mean(fp_score) * diag_score\n",
    "\n",
    "\n",
    "def diagonality_index(corr):\n",
    "    n_contrasts, n_subj = corr.shape[0], corr.shape[1]\n",
    "    diag_index = np.zeros((n_contrasts, n_subj))\n",
    "    for i in range(n_contrasts):\n",
    "        mat = corr[i]\n",
    "        for r in range(mat.shape[0]):\n",
    "            off_diag_elements = []\n",
    "            for c in range(mat.shape[1]):\n",
    "                if r == c:\n",
    "                    diag_element = mat[r, c]\n",
    "                else:\n",
    "                    off_diag_elements.append(mat[r, c])\n",
    "            diag_index[i, r] = (\n",
    "                np.mean(diag_element - np.array(off_diag_elements)) * diag_element\n",
    "            )\n",
    "    return diag_index\n",
    "\n",
    "\n",
    "def cliffs_delta(group1, group2):\n",
    "    \"\"\"\n",
    "    Calculate Cliff's Delta effect size between two groups.\n",
    "\n",
    "    Parameters:\n",
    "    group1, group2 : array-like\n",
    "        The two groups to compare\n",
    "\n",
    "    Returns:\n",
    "    float : Cliff's Delta (-1 to +1)\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays for efficient computation\n",
    "    g1, g2 = np.array(group1), np.array(group2)\n",
    "\n",
    "    # Use broadcasting to compute all pairwise comparisons at once\n",
    "    greater = g1[:, None] > g2\n",
    "    less = g1[:, None] < g2\n",
    "\n",
    "    # Sum up differences and normalize\n",
    "    dominance = np.sum(greater) - np.sum(less)\n",
    "    delta = dominance / (len(g1) * len(g2))\n",
    "\n",
    "    return delta\n",
    "\n",
    "\n",
    "def perm_ttest(a, b, num_permutations=1000, seed=42):\n",
    "    def statistic(a, b):\n",
    "        return ttest_rel(a, b).statistic\n",
    "\n",
    "    delta = cliffs_delta(a, b)\n",
    "\n",
    "    res = permutation_test(\n",
    "        (a, b),\n",
    "        statistic,\n",
    "        vectorized=False,\n",
    "        permutation_type=\"samples\",\n",
    "        alternative=\"two-sided\",\n",
    "        random_state=seed,\n",
    "        n_resamples=num_permutations,\n",
    "    )\n",
    "    return res.statistic, res.pvalue, delta\n",
    "\n",
    "\n",
    "def compute_statistics(\n",
    "    df,\n",
    "    contrasts,\n",
    "    main_model=\"DeepTaskGen\",\n",
    "    compare_models=(\"Average\", \"Retest\", \"Linear Regression\"),\n",
    "    metric=\"Corr\",\n",
    "):\n",
    "    def run_permutation_test(cont, model):\n",
    "        t_stat, p_value, cliff, cohen = perm_ttest(\n",
    "            df[(df[\"Contrast\"] == cont) & (df[\"Method\"] == main_model)][metric],\n",
    "            df[(df[\"Contrast\"] == cont) & (df[\"Method\"] == model)][metric],\n",
    "        )\n",
    "        return {\n",
    "            \"Contrast\": cont,\n",
    "            \"Model\": model,\n",
    "            \"t_stat\": t_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"cliff\": cliff,\n",
    "        }\n",
    "\n",
    "    perm_results = Parallel(n_jobs=-1)(\n",
    "        delayed(run_permutation_test)(cont, model)\n",
    "        for cont in contrasts\n",
    "        for model in compare_models\n",
    "    )\n",
    "    perm_results = pd.DataFrame(perm_results)\n",
    "    perm_results[\"p_value_fdr\"] = fdrcorrection(perm_results[\"p_value\"])[1]\n",
    "    return perm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HCP subjects\n",
    "ABS_PATH = op.abspath(op.join(os.getcwd(), \"../..\"))\n",
    "TEST_SUBJ = op.join(\n",
    "    ABS_PATH, \"transfer_learning/hcp_development/data/hcpd_test_ids.txt\"\n",
    ")\n",
    "\n",
    "RESULTS_PATH = op.join(ABS_PATH, \"transfer_learning/hcp_development/results/figures\")\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "\n",
    "INCLUDE_CONTRASTS = (\n",
    "    \"EMOTION FACES-SHAPES\",\n",
    "    \"GAMBLING REWARD\",\n",
    ")\n",
    "\n",
    "# DeepTaskGen â€“ Finetuned = Red, DeepTaskGen - NoFinetune = Yellow, Tavor = Blue\n",
    "PALETTE = {\n",
    "    \"Finetune\": \"#AE3033\",\n",
    "    \"No Finetune\": \"#FBDF4F\",\n",
    "    \"Linear Regression\": \"#283F94\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRED_BY_MODEL = {\n",
    "    \"EMOTION\\nFACES-SHAPES\": {\n",
    "        \"Linear Regression\": op.join(\n",
    "            ABS_PATH,\n",
    "            \"transfer_learning/hcp_development/results/tavor/corr_scores_emotion_faces-shapes.npy\",\n",
    "        ),\n",
    "        \"No Finetune\": op.join(\n",
    "            ABS_PATH,\n",
    "            \"transfer_learning/hcp_development/results/nofinetune-attentionunet/corr_scores_emotion_faces-shapes.npy\",\n",
    "        ),\n",
    "        \"Finetune\": op.join(\n",
    "            ABS_PATH,\n",
    "            \"transfer_learning/hcp_development/results/finetuned_50_0.001_gambling-reward_attentionunet_gm_20/corr_scores_emotion_faces-shapes.npy\",\n",
    "        ),\n",
    "    },\n",
    "    \"GAMBLING\\nREWARD\": {\n",
    "        \"Linear Regression\": op.join(\n",
    "            ABS_PATH,\n",
    "            \"transfer_learning/hcp_development/results/tavor/corr_scores_gambling_reward.npy\",\n",
    "        ),\n",
    "        \"No Finetune\": op.join(\n",
    "            ABS_PATH,\n",
    "            \"transfer_learning/hcp_development/results/nofinetune-attentionunet/corr_scores_gambling_reward.npy\",\n",
    "        ),\n",
    "        \"Finetune\": op.join(\n",
    "            ABS_PATH,\n",
    "            \"transfer_learning/hcp_development/results/finetuned_50_0.001_emotion-faces-shapes_attentionunet_gm_20/corr_scores_gambling_reward.npy\",\n",
    "        ),\n",
    "    },\n",
    "}\n",
    "corr_by_model = {}\n",
    "dice_auc_by_model = {}\n",
    "for cont in PRED_BY_MODEL.keys():\n",
    "    corr_by_model[cont] = {}\n",
    "    dice_auc_by_model[cont] = {}\n",
    "    for model in PRED_BY_MODEL[cont].keys():\n",
    "        corr_by_model[cont][model] = np.load(PRED_BY_MODEL[cont][model])\n",
    "        dice_auc_by_model[cont][model] = np.load(\n",
    "            PRED_BY_MODEL[cont][model].replace(\"corr_scores\", \"dice_auc\")\n",
    "        ).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faces\n",
    "corr_df = pd.DataFrame()\n",
    "fp_df = pd.DataFrame()\n",
    "fp_norm_df = pd.DataFrame()\n",
    "dice_auc_df = pd.DataFrame()\n",
    "diag_index_df = pd.DataFrame()\n",
    "diag_index_norm_df = pd.DataFrame()\n",
    "for cont in PRED_BY_MODEL.keys():\n",
    "    for model in PRED_BY_MODEL[cont].keys():\n",
    "        corr_df = pd.concat(\n",
    "            [\n",
    "                corr_df,\n",
    "                pd.DataFrame(\n",
    "                    extract_diagonal(np.squeeze(corr_by_model[cont][model])).T,\n",
    "                    columns=[\"Reconstruction Accuracy\"],\n",
    "                ).assign(Method=model, Contrast=cont),\n",
    "            ]\n",
    "        )\n",
    "        fp_df = pd.concat(\n",
    "            [\n",
    "                fp_df,\n",
    "                pd.DataFrame(\n",
    "                    [fingerprinting_score(np.squeeze(corr_by_model[cont][model]))],\n",
    "                    columns=[\"Fingerprint\"],\n",
    "                ).assign(Method=model, Contrast=cont),\n",
    "            ]\n",
    "        )\n",
    "        diag_index_df = pd.concat(\n",
    "            [\n",
    "                diag_index_df,\n",
    "                pd.DataFrame(\n",
    "                    diagonality_index(\n",
    "                        np.expand_dims(corr_by_model[cont][model], axis=0)\n",
    "                    ).reshape(-1, 1),\n",
    "                    columns=[\"Diagonality Index\"],\n",
    "                ).assign(Method=model, Contrast=cont),\n",
    "            ]\n",
    "        )\n",
    "        dice_auc_df = pd.concat(\n",
    "            [\n",
    "                dice_auc_df,\n",
    "                pd.DataFrame(\n",
    "                    dice_auc_by_model[cont][model].reshape(-1, 1),\n",
    "                    columns=[\"Dice AUC\"],\n",
    "                ).assign(Method=model, Contrast=cont),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "results_data_path = op.join(RESULTS_PATH, \"results_data\")\n",
    "os.makedirs(results_data_path, exist_ok=True)\n",
    "corr_df.to_csv(\n",
    "    op.join(results_data_path, \"corr_hcpd.csv\"),\n",
    "    index=False,\n",
    ")\n",
    "dice_auc_df.to_csv(\n",
    "    op.join(results_data_path, \"dice_auc_hcpd.csv\"),\n",
    "    index=False,\n",
    ")\n",
    "fp_df.to_csv(\n",
    "    op.join(results_data_path, \"fp_hcpd.csv\"),\n",
    "    index=False,\n",
    ")\n",
    "diag_index_df.to_csv(\n",
    "    op.join(results_data_path, \"diag_index_hcpd.csv\"),\n",
    "    index=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Reconstruction Accuracy\n",
    "plt.figure(figsize=(14, 10), dpi=300)\n",
    "sns.boxplot(\n",
    "    data=corr_df,\n",
    "    x=\"Contrast\",\n",
    "    y=\"Corr\",\n",
    "    hue=\"Method\",\n",
    "    palette=PALETTE,\n",
    "    flierprops={\"marker\": \"d\", \"markerfacecolor\": \"black\", \"markersize\": 5},\n",
    ")\n",
    "plt.ylim(-0.2, 0.8)  # Set y-axis limits\n",
    "plt.ylabel(\"Reconstruction\")\n",
    "plt.legend()\n",
    "sns.despine(offset=10, trim=True)\n",
    "plt.savefig(op.join(RESULTS_PATH, \"recon.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Dice AUC\n",
    "plt.figure(figsize=(14, 10), dpi=300)\n",
    "sns.boxplot(\n",
    "    data=dice_auc_df,\n",
    "    x=\"Contrast\",\n",
    "    y=\"Dice AUC\",\n",
    "    hue=\"Method\",\n",
    "    palette=PALETTE,\n",
    "    flierprops={\"marker\": \"d\", \"markerfacecolor\": \"black\", \"markersize\": 5},\n",
    ").set()\n",
    "plt.ylim(0.05, 0.30)  # Set y-axis limits\n",
    "sns.despine(offset=10, trim=True)\n",
    "plt.legend(loc=\"upper center\", ncol=4).set_visible(False)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.savefig(op.join(RESULTS_PATH, \"dice_auc.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Fingerprinting Score\n",
    "plt.figure(figsize=(14, 10), dpi=300)\n",
    "sns.pointplot(data=fp_df, x=\"Contrast\", y=\"Fingerprint\", hue=\"Method\", palette=PALETTE)\n",
    "plt.ylim(0, 1)  # Set y-axis limits\n",
    "sns.despine(offset=10, trim=True)\n",
    "plt.legend()\n",
    "plt.ylabel(\"Fingerprinting Score\")\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "plt.savefig(op.join(RESULTS_PATH, \"fp.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Diagonality Index\n",
    "plt.figure(figsize=(14, 10), dpi=300)\n",
    "ax = sns.boxplot(\n",
    "    data=diag_index_df,\n",
    "    x=\"Contrast\",\n",
    "    y=\"Diagonality Index\",\n",
    "    hue=\"Method\",\n",
    "    palette=PALETTE,\n",
    "    flierprops={\"marker\": \"d\", \"markerfacecolor\": \"black\", \"markersize\": 5},\n",
    ")\n",
    "ax.set(\n",
    "    yticks=[\n",
    "        -0.05,\n",
    "        0,\n",
    "        0.05,\n",
    "        0.1,\n",
    "        0.15,\n",
    "    ],  # Meaningful tick marks\n",
    ")\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "plt.ylim(-0.05, 0.151)  # Set y-axis limits\n",
    "sns.despine(offset=10, trim=True)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"\")\n",
    "plt.legend(loc=\"upper center\", ncol=4).set_visible(False)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.savefig(op.join(RESULTS_PATH, \"diag_index.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First save the tables into .csv files.\n",
    "corr_df.groupby([\"Contrast\", \"Method\"]).describe().to_csv(\n",
    "    op.join(RESULTS_PATH, \"tables/corr_hcpd.csv\"),\n",
    "    float_format=\"%.3f\",\n",
    "    decimal=\",\",\n",
    "    sep=\";\",\n",
    ")\n",
    "dice_auc_df.groupby([\"Contrast\", \"Method\"]).describe().to_csv(\n",
    "    op.join(RESULTS_PATH, \"tables/dice_auc_hcpd.csv\"),\n",
    "    float_format=\"%.3f\",\n",
    "    decimal=\",\",\n",
    "    sep=\";\",\n",
    ")\n",
    "fp_df.groupby([\"Contrast\", \"Method\"]).mean().to_csv(\n",
    "    op.join(RESULTS_PATH, \"tables/fp_hcpd.csv\"),\n",
    "    float_format=\"%.3f\",\n",
    "    decimal=\",\",\n",
    "    sep=\";\",\n",
    ")\n",
    "diag_index_df.groupby([\"Contrast\", \"Method\"]).mean().to_csv(\n",
    "    op.join(RESULTS_PATH, \"tables/diag_index_hcpd.csv\"),\n",
    "    float_format=\"%.3f\",\n",
    "    decimal=\",\",\n",
    "    sep=\";\",\n",
    ")\n",
    "\n",
    "# Post-hoc Comparisons between models in terms of various performance metrics\n",
    "# Significance is determined using permutation tests with 1000 permutations.\n",
    "target_contrasts = [\"EMOTION\\nFACES-SHAPES\", \"GAMBLING\\nREWARD\"]\n",
    "target_models = (\"Linear Regression\", \"No Finetune\")\n",
    "compute_statistics(  # Reconstruction Accuracy\n",
    "    corr_df,\n",
    "    target_contrasts,\n",
    "    main_model=\"Finetune\",\n",
    "    compare_models=target_models,\n",
    "    metric=\"Reconstruction Accuracy\",\n",
    ").to_csv(\n",
    "    op.join(RESULTS_PATH, \"tables/corr_hcpd_ttest.csv\"),\n",
    "    float_format=\"%.3f\",\n",
    "    index=False,\n",
    "    decimal=\",\",\n",
    "    sep=\";\",\n",
    ")\n",
    "compute_statistics(  # Dice AUC\n",
    "    dice_auc_df,\n",
    "    target_contrasts,\n",
    "    main_model=\"Finetune\",\n",
    "    compare_models=target_models,\n",
    "    metric=\"Dice AUC\",\n",
    ").to_csv(\n",
    "    op.join(RESULTS_PATH, \"tables/dice_auc_hcpd_ttest.csv\"),\n",
    "    float_format=\"%.3f\",\n",
    "    index=False,\n",
    "    decimal=\",\",\n",
    "    sep=\";\",\n",
    ")\n",
    "compute_statistics(  # Diagonality Index\n",
    "    diag_index_df,\n",
    "    target_contrasts,\n",
    "    main_model=\"Finetune\",\n",
    "    compare_models=target_models,\n",
    "    metric=\"Diagonality Index\",\n",
    ").to_csv(\n",
    "    op.join(RESULTS_PATH, \"tables/diag_index_hcpd_ttest.csv\"),\n",
    "    float_format=\"%.3f\",\n",
    "    index=False,\n",
    "    decimal=\",\",\n",
    "    sep=\";\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(\"Reconstruction Accuracy\")\n",
    "print(\n",
    "    pd.read_csv(\n",
    "        op.join(RESULTS_PATH, \"tables/corr_hcpd_ttest.csv\"),\n",
    "        sep=\";\",\n",
    "        decimal=\",\",\n",
    "        index_col=None,\n",
    "    )\n",
    ")\n",
    "print(\"\\nDice AUC\")\n",
    "print(\n",
    "    pd.read_csv(\n",
    "        op.join(RESULTS_PATH, \"tables/dice_auc_hcpd_ttest.csv\"),\n",
    "        sep=\";\",\n",
    "        decimal=\",\",\n",
    "        index_col=None,\n",
    "    )\n",
    ")\n",
    "print(\"\\nFingerprinting\")\n",
    "print(\n",
    "    pd.read_csv(\n",
    "        op.join(RESULTS_PATH, \"tables/fp_hcpd.csv\"),\n",
    "        sep=\";\",\n",
    "        decimal=\",\",\n",
    "        index_col=None,\n",
    "    )\n",
    ")\n",
    "print(\"\\nDiagonality Index\")\n",
    "print(\n",
    "    pd.read_csv(\n",
    "        op.join(RESULTS_PATH, \"tables/diag_index_hcpd_ttest.csv\"),\n",
    "        sep=\";\",\n",
    "        decimal=\",\",\n",
    "        index_col=None,\n",
    "    )\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainvolcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
