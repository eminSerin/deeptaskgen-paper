{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import permutation_test, ttest_rel\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "sys.path.append(op.abspath(op.join(op.abspath(\"\"), \"..\")))\n",
    "from utils.utils import get_contrasts\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"talk\", font_scale=1.2, rc={\"axes.labelpad\": 10})\n",
    "pd.set_option(\"display.float_format\", \"{:.3}\".format)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "pd.set_option(\"display.float_format\", \"{:.3}\".format)\n",
    "\n",
    "WORKING_DIR = op.join(Path.cwd().parent, \"experiments/visualization\")\n",
    "fig_dir = op.join(WORKING_DIR, \"figures\")\n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "results_data_path = op.join(WORKING_DIR, \"results_data\")\n",
    "os.makedirs(results_data_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "def load_corr_wrapper(path):\n",
    "    return np.load(path)\n",
    "\n",
    "\n",
    "def extract_diagonal(mat):\n",
    "    n_dims = len(mat.shape)\n",
    "    if n_dims == 3:\n",
    "        raise ValueError(\"Input matrix must be 2D\")\n",
    "    return np.array([mat[i, i] for i in range(mat.shape[0])])\n",
    "\n",
    "\n",
    "def fingerprinting_score(corr_matrix):\n",
    "    \"\"\"\n",
    "    Computes the fingerprinting score from a correlation matrix.\n",
    "\n",
    "    Parameters:\n",
    "    corr_matrix (numpy.ndarray): A 2D numpy array containing the correlation matrix.\n",
    "\n",
    "    Returns:\n",
    "    float: The fingerprinting score.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store the fingerprinting score for each row\n",
    "    fp_score = []\n",
    "    diag_score = np.diag(corr_matrix).mean()\n",
    "    # Iterate over each row in the correlation matrix\n",
    "    for row_index, row in enumerate(corr_matrix):\n",
    "        # Check if the maximum value in the row is on the diagonal\n",
    "        is_max_on_diagonal = np.argmax(row) == row_index\n",
    "\n",
    "        # Check if the diagonal element is the only occurrence of that value in the row\n",
    "        is_unique_in_row = np.count_nonzero(row == row[row_index]) == 1\n",
    "\n",
    "        # If both conditions are met, append True to the fp_score list, otherwise append False\n",
    "        fp_score.append(is_max_on_diagonal and is_unique_in_row)\n",
    "\n",
    "    # Calculate the fingerprinting score as the mean of the fp_score list\n",
    "    return np.mean(fp_score) * diag_score\n",
    "\n",
    "\n",
    "def diagonality_index(corr):\n",
    "    n_contrasts, n_subj = corr.shape[0], corr.shape[1]\n",
    "    diag_index = np.zeros((n_contrasts, n_subj))\n",
    "    for i in range(n_contrasts):\n",
    "        mat = corr[i]\n",
    "        for r in range(mat.shape[0]):\n",
    "            off_diag_elements = []\n",
    "            for c in range(mat.shape[1]):\n",
    "                if r == c:\n",
    "                    diag_element = mat[r, c]\n",
    "                else:\n",
    "                    off_diag_elements.append(mat[r, c])\n",
    "            diag_index[i, r] = (\n",
    "                np.mean(diag_element - np.array(off_diag_elements)) * diag_element\n",
    "            )\n",
    "    return diag_index\n",
    "\n",
    "\n",
    "def cliffs_delta(group1, group2):\n",
    "    \"\"\"\n",
    "    Calculate Cliff's Delta effect size between two groups.\n",
    "\n",
    "    Parameters:\n",
    "    group1, group2 : array-like\n",
    "        The two groups to compare\n",
    "\n",
    "    Returns:\n",
    "    float : Cliff's Delta (-1 to +1)\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays for efficient computation\n",
    "    g1, g2 = np.array(group1), np.array(group2)\n",
    "\n",
    "    # Use broadcasting to compute all pairwise comparisons at once\n",
    "    greater = g1[:, None] > g2\n",
    "    less = g1[:, None] < g2\n",
    "\n",
    "    # Sum up differences and normalize\n",
    "    dominance = np.sum(greater) - np.sum(less)\n",
    "    delta = dominance / (len(g1) * len(g2))\n",
    "\n",
    "    return delta\n",
    "\n",
    "\n",
    "def perm_ttest(a, b, num_permutations=1000, seed=42):\n",
    "    def statistic(a, b):\n",
    "        return ttest_rel(a, b).statistic\n",
    "\n",
    "    delta = cliffs_delta(a, b)\n",
    "\n",
    "    res = permutation_test(\n",
    "        (a, b),\n",
    "        statistic,\n",
    "        vectorized=False,\n",
    "        permutation_type=\"samples\",\n",
    "        alternative=\"two-sided\",\n",
    "        random_state=seed,\n",
    "        n_resamples=num_permutations,\n",
    "    )\n",
    "    return res.statistic, res.pvalue, delta\n",
    "\n",
    "\n",
    "def compute_statistics(\n",
    "    df,\n",
    "    contrasts,\n",
    "    main_model=\"DeepTaskGen\",\n",
    "    compare_models=(\"Average\", \"Retest\", \"Linear Regression\"),\n",
    "    metric=\"Corr\",\n",
    "):\n",
    "    def run_permutation_test(cont, model):\n",
    "        t_stat, p_value, cliff, cohen = perm_ttest(\n",
    "            df[(df[\"Contrast\"] == cont) & (df[\"Method\"] == main_model)][metric],\n",
    "            df[(df[\"Contrast\"] == cont) & (df[\"Method\"] == model)][metric],\n",
    "        )\n",
    "        return {\n",
    "            \"Contrast\": cont,\n",
    "            \"Model\": model,\n",
    "            \"t_stat\": t_stat,\n",
    "            \"p_value\": p_value,\n",
    "            \"cliff\": cliff,\n",
    "        }\n",
    "\n",
    "    perm_results = Parallel(n_jobs=-1)(\n",
    "        delayed(run_permutation_test)(cont, model)\n",
    "        for cont in contrasts\n",
    "        for model in compare_models\n",
    "    )\n",
    "    perm_results = pd.DataFrame(perm_results)\n",
    "    perm_results[\"p_value_fdr\"] = fdrcorrection(perm_results[\"p_value\"])[1]\n",
    "    return perm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HCP subjects\n",
    "ABS_PATH = sys.path[-1]\n",
    "SUBJ_LIST = np.genfromtxt(\n",
    "    op.join(WORKING_DIR, \"training/data/hcp_test_ids.txt\"), dtype=str\n",
    ")\n",
    "TEST_SUBJ = op.join(ABS_PATH, \"training/data/hcp_test_ids.txt\")\n",
    "\n",
    "RESULTS_PATH = op.join(ABS_PATH, \"training/results/figures\")\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "\n",
    "CORR_SCORES = {\n",
    "    \"Average\": op.join(WORKING_DIR, \"training/results/corr_scores_group_avg.npy\"),\n",
    "    \"Retest\": op.join(WORKING_DIR, \"training/results/corr_scores_retest.npy\"),\n",
    "    \"Linear Regression\": op.join(\n",
    "        WORKING_DIR, \"training/results/hcp-ya_tavor/corr_scores_tavor.npy\"\n",
    "    ),\n",
    "    \"DeepTaskGen\": op.join(\n",
    "        WORKING_DIR,\n",
    "        \"training/results-experiment/attentionunet_100_0.001_gm/corr_scores_deeptaskgen.npy\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "corr_by_model = {}\n",
    "dice_auc_by_model = {}\n",
    "for model in CORR_SCORES.keys():\n",
    "    corr_by_model[model] = np.load(CORR_SCORES[model])\n",
    "    dice_auc_by_model[model] = np.load(\n",
    "        CORR_SCORES[model].replace(\"corr_scores\", \"dice-auc_scores\")\n",
    "    ).transpose()\n",
    "\n",
    "INCLUDE_CONTRASTS = (\n",
    "    \"EMOTION FACES-SHAPES\",\n",
    "    \"GAMBLING REWARD\",\n",
    "    \"WM 2BK-0BK\",\n",
    "    \"LANGUAGE MATH-STORY\",\n",
    "    \"RELATIONAL REL\",\n",
    "    \"SOCIAL TOM-RANDOM\",\n",
    "    \"MOTOR AVG\",\n",
    ")\n",
    "\n",
    "CONTRASTS = get_contrasts()\n",
    "CONTRASTS = np.array([f\"{contrast[0]} {contrast[2]}\" for contrast in CONTRASTS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.DataFrame()\n",
    "fp_df = pd.DataFrame()\n",
    "fp_norm_df = pd.DataFrame()\n",
    "dice_auc_df = pd.DataFrame()\n",
    "diag_index_df = pd.DataFrame()\n",
    "rel_diag_index_df = pd.DataFrame()\n",
    "diag_index_norm_df = pd.DataFrame()\n",
    "for model in corr_by_model.keys():\n",
    "    diag_index = diagonality_index(corr_by_model[model])\n",
    "    for c, cont in enumerate(CONTRASTS):\n",
    "        temp_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Subject\": SUBJ_LIST.flatten(),\n",
    "                \"Reconstruction Accuracy\": extract_diagonal(\n",
    "                    np.squeeze(corr_by_model[model][c])\n",
    "                ).flatten(),\n",
    "            }\n",
    "        ).assign(Method=model, Contrast=cont)\n",
    "        corr_df = pd.concat([corr_df, temp_df], ignore_index=True)\n",
    "        temp_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Subject\": SUBJ_LIST.flatten(),\n",
    "                \"Fingerprint\": fingerprinting_score(\n",
    "                    np.squeeze(corr_by_model[model][c])\n",
    "                ),\n",
    "            }\n",
    "        ).assign(Method=model, Contrast=cont)\n",
    "        fp_df = pd.concat([fp_df, temp_df], ignore_index=True)\n",
    "        temp_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Subject\": SUBJ_LIST.flatten(),\n",
    "                \"Dice AUC\": dice_auc_by_model[model][c],\n",
    "            }\n",
    "        ).assign(Method=model, Contrast=cont)\n",
    "        dice_auc_df = pd.concat([dice_auc_df, temp_df], ignore_index=True)\n",
    "        temp_df = pd.DataFrame(\n",
    "            {\n",
    "                \"Subject\": SUBJ_LIST.flatten(),\n",
    "                \"Diagonality Index\": diag_index[c],\n",
    "            }\n",
    "        ).assign(Method=model, Contrast=cont)\n",
    "        diag_index_df = pd.concat([diag_index_df, temp_df], ignore_index=True)\n",
    "\n",
    "# Save all dataframes to csv files\n",
    "corr_df.to_csv(\n",
    "    op.join(results_data_path, \"corr_hcp.csv\"),\n",
    "    index=False,\n",
    ")\n",
    "fp_df.to_csv(\n",
    "    op.join(results_data_path, \"fp_hcp.csv\"),\n",
    "    index=False,\n",
    ")\n",
    "dice_auc_df.to_csv(\n",
    "    op.join(results_data_path, \"dice_auc_hcp.csv\"),\n",
    "    index=False,\n",
    ")\n",
    "diag_index_df.to_csv(\n",
    "    op.join(results_data_path, \"diag_index_hcp.csv\"),\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot HCP Results\n",
    "corr_df = pd.read_csv(op.join(results_data_path, \"corr_hcp.csv\"))\n",
    "fp_df = pd.read_csv(op.join(results_data_path, \"fp_hcp.csv\"))\n",
    "dice_auc_df = pd.read_csv(op.join(results_data_path, \"dice_auc_hcp.csv\"))\n",
    "diag_index_df = pd.read_csv(op.join(results_data_path, \"diag_index_hcp.csv\"))\n",
    "# Average = Dark Gray, BrainVolCNN = Red, Retest = Yellow, Linear Regression = Blue\n",
    "PALETTE = {\n",
    "    \"Average\": \"#A9A9A9\",\n",
    "    \"Retest\": \"#FBDF4F\",\n",
    "    \"Linear Regression\": \"#283F94\",\n",
    "    \"DeepTaskGen\": \"#AE3033\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOT RESULTS FOR ALL 47 TASK CONTRAST MAPS\n",
    "\n",
    "# Plot Reconstruction Accuracy\n",
    "plt.figure(figsize=(40, 15), dpi=300)\n",
    "sns.boxplot(data=corr_df, x=\"Contrast\", y=\"Corr\", hue=\"Method\", palette=PALETTE)\n",
    "plt.ylim(-0.2, 1.05)  # Set y-axis limits\n",
    "plt.legend(loc=\"upper center\", ncol=4)\n",
    "sns.despine(offset=10, trim=True)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Reconstruction\")\n",
    "plt.savefig(op.join(RESULTS_PATH, \"recon_all_maps.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Dice AUC Score\n",
    "plt.figure(figsize=(40, 15), dpi=300)\n",
    "sns.boxplot(data=dice_auc_df, x=\"Contrast\", y=\"Dice AUC\", hue=\"Method\", palette=PALETTE)\n",
    "plt.ylim(0.10, 0.36)  # Set y-axis limits\n",
    "plt.legend(loc=\"upper center\", ncol=4)\n",
    "sns.despine(offset=10, trim=True)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Dice AUC\")\n",
    "plt.savefig(op.join(RESULTS_PATH, \"dice_auc_all_maps.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Fingerprinting Score\n",
    "plt.figure(figsize=(40, 15), dpi=300)\n",
    "sns.pointplot(data=fp_df, x=\"Contrast\", y=\"Fingerprint\", hue=\"Method\", palette=PALETTE)\n",
    "plt.ylim(-0.05, 1.05)  # Set y-axis limits\n",
    "sns.despine(offset=10, trim=True)\n",
    "plt.legend(loc=\"upper center\", ncol=4)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Discriminbility\")\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "plt.savefig(op.join(RESULTS_PATH, \"disc_all_maps.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Diagonality Index\n",
    "plt.figure(figsize=(40, 15), dpi=300)\n",
    "ax = sns.pointplot(\n",
    "    data=diag_index_df,\n",
    "    x=\"Contrast\",\n",
    "    y=\"Diagonality Index\",\n",
    "    hue=\"Method\",\n",
    "    palette=PALETTE,\n",
    ")\n",
    "ax.set_yscale(\"symlog\", linthresh=0.05)\n",
    "ax.set(\n",
    "    ylim=(-0.001, 0.25),  # Slightly beyond your data range for padding\n",
    "    yticks=[\n",
    "        0,\n",
    "        0.03,\n",
    "        0.05,\n",
    "        0.1,\n",
    "        0.25,\n",
    "    ],  # Meaningful tick marks\n",
    ")\n",
    "sns.despine(offset=10, trim=True)\n",
    "plt.legend(loc=\"upper center\", ncol=4).set_visible(False)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.savefig(op.join(fig_dir, \"diag_index_all_maps.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_sort_df(df, INCLUDE_CONTRASTS):\n",
    "    \"\"\"\n",
    "    Filters and sorts a DataFrame based on the specified contrasts.\n",
    "\n",
    "    Parameters:\n",
    "    - corr_df: DataFrame to be filtered and sorted.\n",
    "    - INCLUDE_CONTRASTS: List of contrasts to include and the order to sort by.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame filtered and sorted based on the specified contrasts.\n",
    "    \"\"\"\n",
    "    # Create boolean mask\n",
    "    mask = df[\"Contrast\"].isin(INCLUDE_CONTRASTS)\n",
    "\n",
    "    # Filter dataframe\n",
    "    df_filtered = df[mask]\n",
    "\n",
    "    # Convert \"Contrast\" column to a categorical type with specified order\n",
    "    df_filtered[\"Contrast\"] = pd.Categorical(\n",
    "        df_filtered[\"Contrast\"], categories=INCLUDE_CONTRASTS, ordered=True\n",
    "    )\n",
    "\n",
    "    # Sort df_filtered by the \"Contrast\" column\n",
    "    df_filtered = df_filtered.sort_values(\"Contrast\")\n",
    "\n",
    "    # Replace spaces with newlines in the \"Contrast\" column\n",
    "    df_filtered[\"Contrast\"] = [\n",
    "        cont.replace(\" \", \"\\n\") for cont in np.array(df_filtered[\"Contrast\"])\n",
    "    ]\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "## PLOT RESULTS ONLY FOR 7 REPRESENTATIVE TASK CONTRAST MAPS\n",
    "# Filter plot df for only the 7 representative contrasts\n",
    "# Plot Reconstruction Accuracy\n",
    "plt.figure(figsize=(25, 10), dpi=300)\n",
    "sns.boxplot(\n",
    "    data=filter_and_sort_df(corr_df, INCLUDE_CONTRASTS),\n",
    "    x=\"Contrast\",\n",
    "    y=\"Corr\",\n",
    "    hue=\"Method\",\n",
    "    palette=PALETTE,\n",
    ")\n",
    "plt.ylim(-0.2, 1.05)  # Set y-axis limits\n",
    "sns.despine(offset=10, trim=True)\n",
    "plt.ylabel(\"Reconstruction\")\n",
    "plt.legend()\n",
    "plt.savefig(op.join(RESULTS_PATH, \"recon_7_maps.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Dice AUC Score\n",
    "plt.figure(figsize=(25, 10), dpi=300)\n",
    "sns.boxplot(\n",
    "    data=filter_and_sort_df(dice_auc_df, INCLUDE_CONTRASTS),\n",
    "    x=\"Contrast\",\n",
    "    y=\"Dice AUC\",\n",
    "    hue=\"Method\",\n",
    "    palette=PALETTE,\n",
    ")\n",
    "plt.ylim(0.10, 0.36)  # Set y-axis limits\n",
    "plt.legend(loc=\"upper center\", ncol=4)\n",
    "sns.despine(offset=10, trim=True)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Dice AUC\")\n",
    "plt.savefig(op.join(RESULTS_PATH, \"dice_auc_7_maps.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Fingerprinting Score\n",
    "plt.figure(figsize=(25, 10), dpi=300)\n",
    "sns.pointplot(\n",
    "    data=filter_and_sort_df(fp_df, INCLUDE_CONTRASTS),\n",
    "    x=\"Contrast\",\n",
    "    y=\"Fingerprint\",\n",
    "    hue=\"Method\",\n",
    "    palette=PALETTE,\n",
    ")\n",
    "plt.ylim(-0.05, 1.05)  # Set y-axis limits\n",
    "sns.despine(offset=10, trim=True)\n",
    "plt.ylabel(\"Fingerprinting Score\")\n",
    "plt.legend()\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "plt.savefig(op.join(RESULTS_PATH, \"disc_7_maps.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot Diagonality Index\n",
    "plt.figure(figsize=(25, 10), dpi=300)\n",
    "ax = sns.pointplot(\n",
    "    data=filter_and_sort_df(diag_index_df, INCLUDE_CONTRASTS),\n",
    "    x=\"Contrast\",\n",
    "    y=\"Diagonality Index\",\n",
    "    hue=\"Method\",\n",
    "    palette=PALETTE,\n",
    ")\n",
    "ax.set_yscale(\"symlog\", linthresh=0.05)\n",
    "ax.set(\n",
    "    ylim=(-0.001, 0.25),  # Slightly beyond your data range for padding\n",
    "    yticks=[\n",
    "        0,\n",
    "        0.03,\n",
    "        0.05,\n",
    "        0.1,\n",
    "        0.25,\n",
    "    ],  # Meaningful tick marks\n",
    ")\n",
    "sns.despine(offset=10, trim=True)\n",
    "plt.legend(loc=\"upper center\", ncol=4).set_visible(False)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.savefig(op.join(fig_dir, \"diag_index_7_maps.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First save the tables into .csv files.\n",
    "os.makedirs(op.join(WORKING_DIR, \"tables/\"), exist_ok=True)\n",
    "corr_df.groupby([\"Contrast\", \"Method\"]).describe().to_csv(\n",
    "    op.join(WORKING_DIR, \"tables/corr_hcp.csv\"),\n",
    "    float_format=\"%.3f\",\n",
    "    decimal=\",\",\n",
    "    sep=\";\",\n",
    ")\n",
    "fp_df.groupby([\"Contrast\", \"Method\"]).describe().to_csv(\n",
    "    op.join(WORKING_DIR, \"tables/fp_hcp.csv\"),\n",
    "    float_format=\"%.3f\",\n",
    "    decimal=\",\",\n",
    "    sep=\";\",\n",
    ")\n",
    "dice_auc_df.groupby([\"Contrast\", \"Method\"]).describe().to_csv(\n",
    "    op.join(WORKING_DIR, \"tables/dice_auc_hcp.csv\"),\n",
    "    float_format=\"%.3f\",\n",
    "    decimal=\",\",\n",
    "    sep=\";\",\n",
    ")\n",
    "diag_index_df.groupby([\"Contrast\", \"Method\"]).describe().to_csv(\n",
    "    op.join(WORKING_DIR, \"tables/diag_index_hcp.csv\"),\n",
    "    float_format=\"%.3f\",\n",
    "    decimal=\",\",\n",
    "    sep=\";\",\n",
    ")\n",
    "\n",
    "# Post-hoc Comparisons between models in terms of various performance metrics\n",
    "# Significance is determined using permutation tests with 1000 permutations.\n",
    "compute_statistics(corr_df, CONTRASTS, metric=\"Reconstruction Accuracy\").to_csv(\n",
    "    op.join(WORKING_DIR, \"tables/corr_hcp_ttest.csv\"),\n",
    "    float_format=\"%.3f\",\n",
    "    decimal=\".\",\n",
    "    sep=\";\",\n",
    ")\n",
    "compute_statistics(dice_auc_df, CONTRASTS, metric=\"Dice AUC\").to_csv(\n",
    "    op.join(WORKING_DIR, \"tables/dice_auc_hcp_ttest.csv\"),\n",
    "    float_format=\"%.3f\",\n",
    "    decimal=\".\",\n",
    "    sep=\";\",\n",
    ")\n",
    "compute_statistics(diag_index_df, CONTRASTS, metric=\"Diagonality Index\").to_csv(\n",
    "    op.join(WORKING_DIR, \"tables/diag_index_hcp_ttest.csv\"),\n",
    "    float_format=\"%.3f\",\n",
    "    decimal=\".\",\n",
    "    sep=\";\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print significant performance differences between models\n",
    "corr_ttest = pd.read_csv(\n",
    "    op.join(WORKING_DIR, \"tables/corr_hcp_ttest.csv\"),\n",
    "    sep=\";\",\n",
    "    decimal=\".\",\n",
    "    index_col=None,\n",
    ")\n",
    "dice_ttest = pd.read_csv(\n",
    "    op.join(WORKING_DIR, \"tables/dice_auc_hcp_ttest.csv\"),\n",
    "    sep=\";\",\n",
    "    decimal=\".\",\n",
    "    index_col=None,\n",
    ")\n",
    "diag_ttest = pd.read_csv(\n",
    "    op.join(WORKING_DIR, \"tables/diag_index_hcp_ttest.csv\"),\n",
    "    sep=\";\",\n",
    "    decimal=\".\",\n",
    "    index_col=None,\n",
    ")\n",
    "\n",
    "print(\"Reconstruction Accuracy\")\n",
    "for model in (\"Average\", \"Retest\", \"Linear Regression\"):\n",
    "    tmp_df = corr_ttest[corr_ttest[\"Model\"] == model]\n",
    "    print(\n",
    "        f\"Model: {model}, \"\n",
    "        f\"Positive: {len(tmp_df.query('t_stat > 0 and p_value_fdr < 0.05'))}, \"\n",
    "        f\"Negative: {len(tmp_df.query('t_stat < 0 and p_value_fdr < 0.05'))}, \"\n",
    "        f\"Non-significant: {len(tmp_df.query('p_value_fdr >= 0.05'))}\"\n",
    "    )\n",
    "print(\"\\nDice AUC\")\n",
    "for model in (\"Average\", \"Retest\", \"Linear Regression\"):\n",
    "    tmp_df = dice_ttest[dice_ttest[\"Model\"] == model]\n",
    "    print(\n",
    "        f\"Model: {model}, \"\n",
    "        f\"Positive: {len(tmp_df.query('t_stat > 0 and p_value_fdr < 0.05'))}, \"\n",
    "        f\"Negative: {len(tmp_df.query('t_stat < 0 and p_value_fdr < 0.05'))}, \"\n",
    "        f\"Non-significant: {len(tmp_df.query('p_value_fdr >= 0.05'))}\"\n",
    "    )\n",
    "print(\"\\nDiagonality Index\")\n",
    "for model in (\"Average\", \"Retest\", \"Linear Regression\"):\n",
    "    tmp_df = diag_ttest[diag_ttest[\"Model\"] == model]\n",
    "    print(\n",
    "        f\"Model: {model}, \"\n",
    "        f\"Positive: {len(tmp_df.query('t_stat > 0 and p_value_fdr < 0.05'))}, \"\n",
    "        f\"Negative: {len(tmp_df.query('t_stat < 0 and p_value_fdr < 0.05'))}, \"\n",
    "        f\"Non-significant: {len(tmp_df.query('p_value_fdr >= 0.05'))}\"\n",
    "    )\n",
    "print(\"\\nFingerprinting\")\n",
    "for model in (\"Average\", \"Retest\", \"Linear Regression\"):\n",
    "    n_better_fingerprint = np.sum(\n",
    "        fp_df[fp_df[\"Method\"] == \"DeepTaskGen\"]\n",
    "        .sort_values(\"Contrast\")[\"Fingerprint\"]\n",
    "        .values\n",
    "        > fp_df[fp_df[\"Method\"] == model].sort_values(\"Contrast\")[\"Fingerprint\"].values\n",
    "    )\n",
    "    print(\n",
    "        f\"Model: {model}, Number of greater fingerprinting scores: {n_better_fingerprint}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainvolcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
